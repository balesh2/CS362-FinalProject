\documentclass[letterpaper,10pt]{article}

\usepackage{geometry}
\usepackage{hyperref}
\usepackage{glossaries}
\usepackage[pdftex]{graphicx}
\usepackage{tikz}
\usepackage{wrapfig}
\usepackage{listings}
\usepackage{color}
\geometry{textheight=8.5in, textwidth=6in}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=bash,
    aboveskip=3mm,
      belowskip=3mm,
	showstringspaces=false,
	  columns=flexible,
	    basicstyle={\small\ttfamily},
	      numbers=none,
	        numberstyle=\tiny\color{gray},
		  keywordstyle=\color{blue},
		    commentstyle=\color{dkgreen},
		      stringstyle=\color{mauve},
		        breaklines=true,
			  breakatwhitespace=true,
			    tabsize=3
			    }

\title{Final Project: Mutation Testing}
\author{Helena~Bales\\ \\ CS362-001 \\ Winter 2017}

\parindent = 0.0 in
\parskip = 0.1 in

\begin{document}
\maketitle

\clearpage
\tableofcontents
\clearpage

\section{Part A - Mutation Testing Of My Dominion Implementation}
	\subsection{Mutation Testing}
		\subsubsection{Mutation Testing of Unit Tests}
		\textbf{Command:} \\ 
		\begin{lstlisting}
		mvn org.pitest:pitest-maven:mutationCoverage 
		\end{lstlisting}

		With pom.xml lines for testing Unit Tests uncommented (see pom.xml).

		\textbf{Output:}\\
		\input{UnitMutateTest}

		\subsubsection{Mutation Testing of Random Tests}
		\textbf{Command: }
		\begin{lstlisting}
		mvn org.pitest:pitest-maven:mutationCoverage 
		\end{lstlisting}

		With pom.xml lines for testing Generated Tests uncommented (see pom.xml).

		\textbf{Initial Output: }
		\input{EvoSuiteMutateTest}

		\textbf{Final Output: }
		\input{MutateALLTest}

		\subsubsection{Commentary on Relative Score from Mutation Tests}
		The first thing to note about the mutation testing on my Unit Tests is that I do not 
		have a full suite of Unit Tests. Since I did not turn in Assignment 1, I am very low 
		on Unit Tests and I do not have time to get the mutation score to approach 100\%. I 
		did however raise the overall percentage from 17\% to 18\% by adding more unit tests. 
		The other statistic that stands out to me on the Mutation Testing of my Unit Tests is 
		that the VoidMethodCallMutator has an extremely low kill-rate of 1\%. I believe this 
		is due to the fact that my unit tests mainly test the return values from functions.

		I had a lot of difficulty with getting Pitest to run on the tests generated by 
		EvoSuite. I eventually got it work by adding more dependencies to the pom.xml file. 
		The first thing I noticed about the output is that all of the mutations survived. 
		This made me think that the EvoSuite-generated tests were not being found by Pitest
		and not that EvoSuite actually covered 0\% of the code. This issue was caused by the 
		way that I was declaring which classes and tests to target. In order to get the 
		EvoSuite tests to run, I removed all direct targeting of classes and tests and allowed
		 Pitest to find them. As such, I was not able to run the Mutation Testing tool only on
		 the EvoSuite-generated tests, and was forced to run it on all the tests. Since I do 
		not have very many Unit Tests, I think that they have skewed the results significantly.

		The Final Output above shows around 30\% coverage for each of the Mutation Tests. 
		This was run on the tests generated by EvoSuite and my Unit Tests, so I believe that 
		the low coverage from the Unit Tests caused many of the misses.
	\subsection{Tools for Mutation Testing}
	Mutation Testing is accomplished using a Java tool. The mutation tool uses a variety of 
	different mutation algorithms to mutate the Dominion implementation. The tool then runs the 
	Dominion Tests and counts how many of the mutations the tests successfully catch and kill. 
	The percentage of mutations killed by the tests is reflective of the thouroughness of the 
	tests. The selected tool will determine the accuracy of these tests and ease of completing 
	them. This section will evaluate the selected tool as well as document the process of 
	selecting a tool.
		\subsubsection{Evaluation of Available Tools}
		\begin{enumerate}
			\item{\textbf{Pitest} - Pitest is a mutation tool that runs tests in parallel.
				It is under active development and the source code is available on 
				Github, along with issue tracking. Usage and debugging of the tool is
				 well-documented.}
			\item{\textbf{MuJava} - MuJava is the oldest of the mutation tools and 
				predates JUnit. The source is only available to researchers.}
			\item{\textbf{Jester} - Jester is no longer under active developement and is 
				no longer supported.}
			\item{\textbf{Jumble} - Jumble has not had a release since 2009 but there is 
				still some support provided.}
		\end{enumerate}
		\subsubsection{Selection of Tool}
		Due to the level of documentation and support provided, I selected Pitest as my 
		mutation tool. The installation through Maven provided some difficulty but I found 
		useful documentation to help me through the issues. I used Pitest to generate the 
		mutation report on my unit tests.
		\subsubsection{Problems Using Selected Tool}
		I had quite a few issues using this tool. The first issue that I encountered was with 
		installing Pitest through Maven. It took me a little while to get all the dependencies
		 sorted out and to get everything installed. I followed the "QuickStart Guide for 
		 Maven" on the Pitest website and used StackOverflow to help debug some of the more 
		 cryptic error messages.

		 After getting Pitest installed and running on my unit tests, I encountered my next 
		 big issue; Pitest errors when run on my tests generated using EvoSuite, my test 
		 generation tool from Assignment 2. Pitest throws a fomatting error on the EvoSuite 
		 tests. This is an issue that I can't seem to find an answer to, as the intersection 
		 of Pitest and EvoSuite is not well-documented. I finally resolved this issue with 
		 the help of my classmates. I was missing dependencies in my pom.xml, which I was 
		 able to resolve.

		 Once I got Pitest to run on the EvoSuite Tests, I still had an issue with the results
		  all being 0\%, indicating that the tests were not being found. To fix this, I 
		 changed the GroupId in the pom.xml from balesh to balesh.dominion. This caused the 
		 EvoSuite-generated tests to be found, resulting in non-zero percentage results.
		\subsubsection{Evaluation of Experience with Selected Tool}
		My experience with this tool was better than my experience with any of the tools from 
		previous assignments. I was able to get it installed without help from the TA, just by
		 following the instructions a couple of times. I am not used to using an IDE and tend 
		towards vim and command line development, so I find using Eclipse to be very 
		challenging and frustrating. I find all the panels and buttons to be stressful and 
		distracting and I would rather just have a box to write my code in and a keyboard.

		That rant aside, I did find Pitest to be fairly easy to use, running one command from 
		Command Line and listing the tests and classes to mutate in the Maven pom.xml. The 
		main issue with the tool is trying to use it with EvoSuite.

\section{Part B - Testing of Classmates' Dominion Implementation}
For Part B of this assignment I will be evaluating River Hendrikson's code, pulled from Github 
on March 19th, 2017.
	\subsection{Evaluating Experience Testing Dominion Implementation}
	Testing River's code went fairly smoothly. I started by pulling it from Github and running
	 the included Unit Tests. I documented the results of this test. Next I attempted to 
	perform the mutation testing on the Unit Tests. Since not all of the Unit Tests passed, I 
	commented out the failing tests in order to run the Mutation Test. I documented the 
	results of the mutation testing on the Unit Tests. Next I generated tests for River's 
	Dominion implementation using EvoSuite. I documented the results of that test as well.

	Testing River's Dominion implementation was easy because the project was well organized 
	and had fairly complete Unit Tests.
	\subsection{Evaluation of Dominion Implementation}
		\subsubsection{Test Results}
		\textbf{Command:}
		\begin{lstlisting}
		mvn test
		\end{lstlisting}

		\textbf{Maven Unit Test Output:}
		\include{hendririMVNTest}

		\subsubsection{Code Coverage Information}
		\textbf{Command: }
		\begin{lstlisting}
		mvn org.pitest:pitest-maven:mutationCoverage
		\end{lstlisting}

		\textbf{Initial Output: }
		\input{hendririMutateTest1}

		\textbf{Changes: }\\
		In order to run a mutation, the tests must all be passing. In order to make this true,
		 I commented out the failing tests from CardTest.\\

		\textbf{Mutation Output: }
		\input{hendririMutateTest}

		\textbf{Command:}
		\begin{lstlisting}
		mvn evosuite:generate evosuite:export  test 
		\end{lstlisting}

		\textbf{EvoSuite Test Output:}
		\input{hendririEvoSuiteTest}

		\subsubsection{Status of Classmates' Dominion Implementation}
		Based on the results of the tests above, it appears that River has a few issue 
		with his implementations of cards, but that his Dominion implementation is 
		otherwise mostly bug-free. The mvn tests show that five card types have failing 
		unit tests. This shows that there is a bug in the implementations of those five 
		card types. 

		There may be other issues in the code that were not caught by River's unit tests. 
		This is shown by the percentage of mutations killed in the Mutation Output above. 
		Since the percentage is not particularly close to 100\%, we can tell that not all 
		of the code is covered by these tests. EvoSuite will be used to generate tests 
		to cover the remainder of the code. The output from the EvoSuite tests are shown 
		under EvoSuite Test Output above. Since no tests failed, EvoSuite did not 
		discover any new bugs in River's Dominion Implementation.
	\subsection{Problems Faced Generating Tests}
	I faced some issues generating tests because EvoSuite was not included as a dependency in 
	 River's pom.xml file. In order to fix this, I modified River's pom.xml to include the 
	packages necessary to successfully run EvoSuite. Once this was completed, I had no issues 
	with generating tests for River's Dominion implementation.
	\subsection{Problems Faced Testing Code}
	Other than the issue with generating tests documented above, I did not have any issues 
	testing the code. Everything ran smoothly and was clear.

\section{Conclusion}
In this project I tested my own Dominion implementation and River Hendrikson's Dominion 
implementation using Unit Tests, Generated Tests, and Mutation Testing. I evaluated the 
effectiveness of the test suites using the mutation testing tool called Pitest. I found that 
neither of my test suites were particularly effective at killing off the mutants. It is not 
surprising that my Unit Tests had low rates of success since I never completed my Unit Test Suite 
(see that I am missing assignment 1). The 0\% success rate of the EvoSuite-generated tests that I 
initially got when mutating was caused by the tests not being found. I was able to fix this issue 
and get some test coverage results from mutating. While my tests were not a particularly good 
example of testing, they did serve the purpose of teaching me to use the mutation tool 
effectively.

The second part of this project, in which I tested River Hendrikson's implementation of Dominion, 
was more successful than the first part. I found two bugs in River's code with the help of his 
unit tests, and was able to get mutation testing results on his unit tests. I was also able to 
generate tests for his code using EvoSuite. Through all of this I was able to evaluate the 
quality and completeness of his Dominion implementation and tests.

\end{document}
